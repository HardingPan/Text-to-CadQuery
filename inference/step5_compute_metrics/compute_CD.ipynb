{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def sample_mesh(stl_path, num_points=10000):\n",
    "    mesh = trimesh.load(stl_path)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "    return points\n",
    "\n",
    "def sample_mesh_normalized(stl_path, num_points=10000):\n",
    "    mesh = trimesh.load(stl_path)\n",
    "    mesh.apply_translation(-mesh.centroid)\n",
    "    scale = np.max(mesh.bounding_box.extents)\n",
    "    mesh.apply_scale(1.0 / scale)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "    return points\n",
    "\n",
    "def chamfer_distance(points1, points2):\n",
    "    tree1 = cKDTree(points1)\n",
    "    tree2 = cKDTree(points2)\n",
    "\n",
    "    dist1, _ = tree1.query(points2)\n",
    "    dist2, _ = tree2.query(points1)\n",
    "\n",
    "    chamfer = np.mean(dist1**2) + np.mean(dist2**2)\n",
    "    return chamfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(points_pred, points_gt, threshold=0.02):\n",
    "    tree_pred = cKDTree(points_pred)\n",
    "    tree_gt = cKDTree(points_gt)\n",
    "\n",
    "    dist_pred_to_gt, _ = tree_gt.query(points_pred)\n",
    "    precision = np.mean(dist_pred_to_gt < threshold)\n",
    "\n",
    "    dist_gt_to_pred, _ = tree_pred.query(points_gt)\n",
    "    recall = np.mean(dist_gt_to_pred < threshold)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "def normalize_mesh(mesh):\n",
    "    \"\"\"\n",
    "    Normalize the mesh to fit inside a unit cube [0, 1]^3\n",
    "    \"\"\"\n",
    "    mesh = mesh.copy()\n",
    "    bounds = mesh.bounds\n",
    "    scale = bounds[1] - bounds[0]\n",
    "    max_extent = np.max(scale)\n",
    "    mesh.apply_translation(-bounds[0])  # move to origin\n",
    "    mesh.apply_scale(1.0 / max_extent)  # scale to fit into [0,1]\n",
    "    return mesh\n",
    "\n",
    "def voxelize_mesh(mesh, voxel_size=0.02):\n",
    "    voxelized = mesh.voxelized(pitch=voxel_size)\n",
    "    return voxelized.matrix \n",
    "\n",
    "def volumetric_iou(mesh1, mesh2, voxel_size=0.02):\n",
    "    # Normalize both meshes to [0,1]^3\n",
    "    mesh1 = normalize_mesh(mesh1)\n",
    "    mesh2 = normalize_mesh(mesh2)\n",
    "\n",
    "    # Voxelize\n",
    "    vox1 = voxelize_mesh(mesh1, voxel_size)\n",
    "    vox2 = voxelize_mesh(mesh2, voxel_size)\n",
    "\n",
    "    # Pad to same shape\n",
    "    shape = np.maximum(vox1.shape, vox2.shape)\n",
    "    vox1_padded = np.zeros(shape, dtype=bool)\n",
    "    vox2_padded = np.zeros(shape, dtype=bool)\n",
    "\n",
    "    vox1_padded[:vox1.shape[0], :vox1.shape[1], :vox1.shape[2]] = vox1\n",
    "    vox2_padded[:vox2.shape[0], :vox2.shape[1], :vox2.shape[2]] = vox2\n",
    "\n",
    "    # Compute IOU\n",
    "    intersection = np.logical_and(vox1_padded, vox2_padded).sum()\n",
    "    union = np.logical_or(vox1_padded, vox2_padded).sum()\n",
    "\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "\n",
    "    iou = intersection / union\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "candidate_list = []\n",
    "candidate_dir = \"./eval_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate in os.listdir(candidate_dir):\n",
    "    if candidate.startswith(\"gemma\"):\n",
    "        candidate_path = os.path.join(candidate_dir, candidate)\n",
    "        with open(candidate_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.endswith(\"Match: Yes\"):\n",
    "                    number = line.split(\":\")[0]\n",
    "                    candidate_list.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_path = './stl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_results = []\n",
    "error_files = []\n",
    "f1_results = []\n",
    "iou_results = []\n",
    "index = 0\n",
    "for filename in tqdm(os.listdir(inference_path)):\n",
    "    if filename.endswith('.stl') and not filename.startswith('._'):\n",
    "        filename_index = filename.split(\".\")[0]\n",
    "        if filename_index in candidate_list:\n",
    "            ground_truth = f'../stlcq/{filename[:4]}/{filename}'\n",
    "            prediction = f'./stl/{filename}'\n",
    "            try:\n",
    "                points_a = sample_mesh_normalized(ground_truth)\n",
    "                points_b = sample_mesh_normalized(prediction)\n",
    "                iou = volumetric_iou(trimesh.load(ground_truth), trimesh.load(prediction), voxel_size=0.02)\n",
    "                iou_results.append(iou)\n",
    "                f1 = f1_score(points_b, points_a)\n",
    "                f1_results.append(f1)\n",
    "                cd = chamfer_distance(points_a, points_b)\n",
    "                cd_results.append(cd)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                error_files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 mean: \",np.mean(f1_results))\n",
    "print(\"F1 median: \",np.median(f1_results))\n",
    "print(\"CD mean: \",np.mean(cd_results)*1000)\n",
    "print(\"CD median: \",np.median(cd_results)*1000)\n",
    "print(\"IOU mean: \",np.mean(iou_results))\n",
    "print(\"IOU median: \",np.median(iou_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slice100k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
